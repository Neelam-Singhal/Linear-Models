{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0e905ad718a08ed27c2c36c9ef4f1f873648da9e7705f623e5afe311501acb5e0",
   "display_name": "Python 3.8.2  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e905ad718a08ed27c2c36c9ef4f1f873648da9e7705f623e5afe311501acb5e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Logistic Regression\n",
    "\n",
    "It is a classificaltion algorithm\n",
    "\n",
    "Sigmoid function transforms a linear line into a curve which has values between 0 and 1. The reason we choose a sigmoid function to model classification problems solved with logistic regression is that we want to make sure that predicted value has a defined range which helps in differentiating the classes.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>SibSp_0</th>\n      <th>SibSp_1</th>\n      <th>...</th>\n      <th>Parch_0</th>\n      <th>Parch_1</th>\n      <th>Parch_2</th>\n      <th>Parch_3</th>\n      <th>Parch_4</th>\n      <th>Parch_5</th>\n      <th>Parch_6</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38.0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>26.0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>35.0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>35.0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv('data_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((891, 25), (891, 24), (891,))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Segregating data in independent and dependent variables\n",
    "\n",
    "X = data.drop(['Survived'], axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "data.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train Test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Age', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female',\n",
       "       'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4',\n",
       "       'SibSp_5', 'SibSp_8', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_3',\n",
       "       'Parch_4', 'Parch_5', 'Parch_6', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# SciKit requires all the data to be normalized. So, lets normalize the data such as Age, Fare using Max_Min_Scalar\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "\n",
    "cols = train_X.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.39792223, 0.06441171, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.11660777, 0.03103473, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.40201142, 0.01571255, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.51073661, 0.29953885, 1.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.32046752, 0.03259623, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.39792223, 0.02822072, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#applying MinMaxScalar to Train data\n",
    "\n",
    "train_X_scales = scalar.fit_transform(train_X)\n",
    "\n",
    "#This converts data into array. We need to convert it back to DataFrame\n",
    "train_X_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.397922  0.064412       0.0       1.0       0.0         1.0       0.0   \n",
       "1  0.116608  0.031035       0.0       0.0       1.0         0.0       1.0   \n",
       "2  0.402011  0.015713       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.252514  0.015412       0.0       0.0       1.0         0.0       1.0   \n",
       "4  0.252514  0.015412       0.0       0.0       1.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      0.0      1.0      0.0  ...      0.0      1.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>SibSp_0</th>\n      <th>SibSp_1</th>\n      <th>SibSp_2</th>\n      <th>...</th>\n      <th>Parch_0</th>\n      <th>Parch_1</th>\n      <th>Parch_2</th>\n      <th>Parch_3</th>\n      <th>Parch_4</th>\n      <th>Parch_5</th>\n      <th>Parch_6</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.397922</td>\n      <td>0.064412</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.116608</td>\n      <td>0.031035</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.402011</td>\n      <td>0.015713</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.252514</td>\n      <td>0.015412</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.252514</td>\n      <td>0.015412</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#convert above array into DataFrame\n",
    "train_X_scaled = pd.DataFrame(train_X_scales, columns=cols)\n",
    "train_X_scaled.head()\n",
    "\n",
    "#you can see that Age and Fare are normalized now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.432177  0.175668       1.0       0.0       0.0         1.0       0.0   \n",
       "1  0.444795  0.025374       0.0       1.0       0.0         1.0       0.0   \n",
       "2  0.406940  0.016892       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.444795  0.015412       0.0       0.0       1.0         0.0       1.0   \n",
       "4  0.217666  0.015176       0.0       0.0       1.0         1.0       0.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>SibSp_0</th>\n      <th>SibSp_1</th>\n      <th>SibSp_2</th>\n      <th>...</th>\n      <th>Parch_0</th>\n      <th>Parch_1</th>\n      <th>Parch_2</th>\n      <th>Parch_3</th>\n      <th>Parch_4</th>\n      <th>Parch_5</th>\n      <th>Parch_6</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.432177</td>\n      <td>0.175668</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.444795</td>\n      <td>0.025374</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.406940</td>\n      <td>0.016892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.444795</td>\n      <td>0.015412</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.217666</td>\n      <td>0.015176</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "#Scale Test_X as well\n",
    "\n",
    "test_X_scales = scalar.fit_transform(test_X)\n",
    "test_X_scaled = pd.DataFrame(test_X_scales, columns=cols)\n",
    "test_X_scaled.head()"
   ]
  },
  {
   "source": [
    "## Implementing Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LOR\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "lor = LOR()\n",
    "\n",
    "lor.fit(train_X_scaled, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7549407114624506"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#f1_score for training data\n",
    "\n",
    "predicted_train = lor.predict(train_X_scaled)\n",
    "f1_train = f1_score(predicted_train, train_y)\n",
    "f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6710526315789473"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# f1_score for Test Data\n",
    "\n",
    "predicted_test = lor.predict(test_X_scaled)\n",
    "f1_test = f1_score(predicted_test, test_y)\n",
    "f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Here, we are using predict which is only outputting 1 and 0s. It dosen't show probabilities. To predict probabilities, we need to use 'predict_proba'\n",
    "predicted_test"
   ]
  },
  {
   "source": [
    "## Making predictions using *predict_proba* function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.22736899, 0.77263101],\n",
       "       [0.79954294, 0.20045706],\n",
       "       [0.92237078, 0.07762922],\n",
       "       ...,\n",
       "       [0.59613503, 0.40386497],\n",
       "       [0.42706317, 0.57293683],\n",
       "       [0.88441223, 0.11558777]])"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# Predicting over train\n",
    "\n",
    "train_predict_proba = lor.predict_proba(train_X_scaled)\n",
    "train_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.77263101, 0.20045706, 0.07762922, 0.10852716, 0.10852716,\n",
       "       0.45666153, 0.0560048 , 0.27910277, 0.10613587, 0.04840931,\n",
       "       0.1589273 , 0.81393042, 0.94735232, 0.9549599 , 0.11181158,\n",
       "       0.79391655, 0.70376561, 0.07773548, 0.11532625, 0.30886784,\n",
       "       0.19804785, 0.81090992, 0.91324932, 0.0595141 , 0.11522465,\n",
       "       0.60972385, 0.12205393, 0.07632641, 0.2472108 , 0.06046812,\n",
       "       0.07835104, 0.61610097, 0.1443882 , 0.45108948, 0.1022025 ,\n",
       "       0.31518987, 0.07240355, 0.803245  , 0.9419146 , 0.09982656,\n",
       "       0.14169387, 0.33166977, 0.9209013 , 0.30007103, 0.07835104,\n",
       "       0.05674924, 0.14666468, 0.71764499, 0.52146383, 0.19789295,\n",
       "       0.0904971 , 0.52065357, 0.07122419, 0.1085226 , 0.64070427,\n",
       "       0.14123268, 0.22870833, 0.76711829, 0.13718442, 0.53791713,\n",
       "       0.07835539, 0.22605419, 0.90791603, 0.55211214, 0.09769595,\n",
       "       0.25698804, 0.08779852, 0.10220698, 0.86557848, 0.09921343,\n",
       "       0.10452378, 0.09329778, 0.4734199 , 0.09913586, 0.13454557,\n",
       "       0.07832721, 0.21538271, 0.4747764 , 0.06436861, 0.31099339,\n",
       "       0.07835539, 0.382422  , 0.08779878, 0.09337869, 0.0826168 ,\n",
       "       0.10305252, 0.82644187, 0.40353293, 0.09620467, 0.45980881,\n",
       "       0.48249989, 0.3649927 , 0.07837265, 0.44994942, 0.12908743,\n",
       "       0.64128485, 0.72850758, 0.10349407, 0.54042341, 0.03189806,\n",
       "       0.10557842, 0.63002229, 0.072953  , 0.0800617 , 0.59466252,\n",
       "       0.71845759, 0.52824561, 0.10217833, 0.11946898, 0.11529955,\n",
       "       0.10449579, 0.92044925, 0.10222891, 0.1022025 , 0.43476685,\n",
       "       0.81852899, 0.83762519, 0.43615781, 0.22242413, 0.07643611,\n",
       "       0.0991681 , 0.13827935, 0.95543566, 0.4339088 , 0.9337098 ,\n",
       "       0.07835104, 0.72226791, 0.29433581, 0.07835539, 0.10851788,\n",
       "       0.61049912, 0.0606733 , 0.09920122, 0.26320989, 0.09225457,\n",
       "       0.89577271, 0.0797315 , 0.0826168 , 0.3824477 , 0.44459754,\n",
       "       0.83022297, 0.94031271, 0.94604702, 0.06854522, 0.11522465,\n",
       "       0.10613587, 0.26977023, 0.07075656, 0.09916273, 0.22605419,\n",
       "       0.58343411, 0.28827747, 0.44756392, 0.73469874, 0.73183426,\n",
       "       0.07835539, 0.10853707, 0.10532088, 0.07835539, 0.07853734,\n",
       "       0.11799148, 0.61610097, 0.16799334, 0.43385608, 0.23801343,\n",
       "       0.92648006, 0.4398706 , 0.88204426, 0.82914595, 0.91798821,\n",
       "       0.07835715, 0.49297171, 0.38284323, 0.81189457, 0.23180626,\n",
       "       0.07295377, 0.13590395, 0.04397313, 0.79529883, 0.84421277,\n",
       "       0.82482096, 0.49509369, 0.06674994, 0.15438639, 0.43320336,\n",
       "       0.55712468, 0.19884725, 0.81600263, 0.11529955, 0.63787418,\n",
       "       0.06643314, 0.62980888, 0.11714659, 0.65080043, 0.0933224 ,\n",
       "       0.803245  , 0.11529971, 0.3412463 , 0.38285245, 0.79781514,\n",
       "       0.65582762, 0.04539566, 0.07834764, 0.33651281, 0.07835104,\n",
       "       0.56101563, 0.10556   , 0.09914022, 0.91910044, 0.46310413,\n",
       "       0.84919902, 0.47412521, 0.27765703, 0.82083781, 0.10122475,\n",
       "       0.77520032, 0.88072117, 0.10249558, 0.43433538, 0.94825755,\n",
       "       0.88511058, 0.22276175, 0.82083781, 0.80036068, 0.11529955,\n",
       "       0.19884725, 0.90469807, 0.09902927, 0.09837913, 0.61610443,\n",
       "       0.12966263, 0.30224015, 0.92041782, 0.0840639 , 0.75521412,\n",
       "       0.16566308, 0.05392828, 0.19804785, 0.03189806, 0.05892349,\n",
       "       0.75734889, 0.59802806, 0.11529971, 0.07835104, 0.6161129 ,\n",
       "       0.86623635, 0.48316297, 0.39884743, 0.63290613, 0.0944039 ,\n",
       "       0.81651637, 0.07855429, 0.07295707, 0.31643576, 0.68007782,\n",
       "       0.76420614, 0.04838999, 0.08779878, 0.21452668, 0.30811917,\n",
       "       0.08256936, 0.19277123, 0.53260076, 0.94578549, 0.62119712,\n",
       "       0.09914022, 0.52378767, 0.10532808, 0.07295377, 0.07835104,\n",
       "       0.08151549, 0.7245559 , 0.67770714, 0.81514907, 0.19884725,\n",
       "       0.0797315 , 0.2058161 , 0.11276987, 0.64763351, 0.18989208,\n",
       "       0.08006673, 0.93251306, 0.9522589 , 0.91013084, 0.10219787,\n",
       "       0.919163  , 0.53463567, 0.80028745, 0.44951641, 0.57066892,\n",
       "       0.05358068, 0.13590395, 0.16346512, 0.4542001 , 0.63482534,\n",
       "       0.94087806, 0.59321101, 0.09330081, 0.56752508, 0.74461566,\n",
       "       0.50584808, 0.03080968, 0.68081175, 0.22828859, 0.23641176,\n",
       "       0.11616862, 0.09984295, 0.19507523, 0.08535932, 0.2089254 ,\n",
       "       0.08005883, 0.43136577, 0.54017395, 0.13238878, 0.10852716,\n",
       "       0.20586651, 0.07762922, 0.33433063, 0.61609982, 0.91692183,\n",
       "       0.12256894, 0.87226825, 0.69052461, 0.03993228, 0.10642312,\n",
       "       0.27937169, 0.411268  , 0.11522465, 0.07835539, 0.40358498,\n",
       "       0.1022207 , 0.32791197, 0.90384933, 0.09916273, 0.06767877,\n",
       "       0.1013621 , 0.37251644, 0.92859331, 0.11181255, 0.65424041,\n",
       "       0.03503905, 0.07835539, 0.0844442 , 0.55971705, 0.20327445,\n",
       "       0.89323723, 0.94258733, 0.87892906, 0.27286831, 0.16092065,\n",
       "       0.20586651, 0.23801343, 0.10529132, 0.05885579, 0.28299798,\n",
       "       0.04914479, 0.6293688 , 0.12776159, 0.14169387, 0.92169046,\n",
       "       0.49160334, 0.07071232, 0.08517098, 0.95606039, 0.92522767,\n",
       "       0.35206096, 0.05156637, 0.26052378, 0.07833285, 0.95160816,\n",
       "       0.95135853, 0.19804785, 0.1266986 , 0.60352518, 0.0878036 ,\n",
       "       0.492531  , 0.4194286 , 0.91934756, 0.96856215, 0.88787821,\n",
       "       0.71764367, 0.03991739, 0.1061351 , 0.61413495, 0.08010794,\n",
       "       0.95555071, 0.01885639, 0.07766975, 0.08514767, 0.62396317,\n",
       "       0.4339088 , 0.23198002, 0.10532349, 0.17333653, 0.11871335,\n",
       "       0.90568608, 0.88896394, 0.07296532, 0.83457372, 0.19692707,\n",
       "       0.7640778 , 0.22837899, 0.59822152, 0.68482779, 0.08779501,\n",
       "       0.78365519, 0.39732641, 0.41966919, 0.74480113, 0.24926475,\n",
       "       0.07833285, 0.68243757, 0.26965494, 0.08256813, 0.42549934,\n",
       "       0.21186017, 0.10613526, 0.25485794, 0.6862222 , 0.10613881,\n",
       "       0.07424602, 0.12689006, 0.09942289, 0.94380629, 0.54882559,\n",
       "       0.19884725, 0.61610097, 0.32403445, 0.09620326, 0.95135853,\n",
       "       0.95099982, 0.93770467, 0.34606098, 0.90686478, 0.23854226,\n",
       "       0.05159692, 0.17259749, 0.23793303, 0.06419268, 0.07835539,\n",
       "       0.05857339, 0.9584977 , 0.10220698, 0.39080377, 0.07071541,\n",
       "       0.78116185, 0.27685203, 0.3421679 , 0.1013621 , 0.76947066,\n",
       "       0.11657088, 0.30113035, 0.14438799, 0.68007782, 0.11535877,\n",
       "       0.45270691, 0.93747606, 0.74458556, 0.59797882, 0.30076264,\n",
       "       0.31280617, 0.87464479, 0.82335704, 0.08300283, 0.05857339,\n",
       "       0.78668149, 0.53468421, 0.28188128, 0.10875313, 0.68007782,\n",
       "       0.0783413 , 0.10613587, 0.93250969, 0.58991282, 0.23783655,\n",
       "       0.05258003, 0.4347189 , 0.1118329 , 0.29433581, 0.06863998,\n",
       "       0.08547486, 0.97220421, 0.45452653, 0.10613541, 0.84857603,\n",
       "       0.0991681 , 0.88549773, 0.13630082, 0.09168428, 0.91013699,\n",
       "       0.57128328, 0.18745368, 0.61610097, 0.63345096, 0.08932957,\n",
       "       0.44796559, 0.35170792, 0.07525645, 0.38908555, 0.96450458,\n",
       "       0.08401737, 0.85364199, 0.08154648, 0.6161129 , 0.67511988,\n",
       "       0.40755444, 0.07835539, 0.89697354, 0.61608982, 0.63787456,\n",
       "       0.41601924, 0.1061621 , 0.70490618, 0.60665234, 0.04997904,\n",
       "       0.1053713 , 0.91303267, 0.16098719, 0.02937676, 0.92290618,\n",
       "       0.10613587, 0.6328185 , 0.93693104, 0.07760687, 0.28422685,\n",
       "       0.64156182, 0.93449073, 0.31443654, 0.630205  , 0.5653824 ,\n",
       "       0.08511968, 0.27444606, 0.37227263, 0.11287105, 0.40740703,\n",
       "       0.94171651, 0.10206437, 0.25194882, 0.11616862, 0.11865451,\n",
       "       0.18668033, 0.08256641, 0.10610626, 0.73011139, 0.12000188,\n",
       "       0.70261742, 0.88943158, 0.61609943, 0.15271791, 0.44975317,\n",
       "       0.0797315 , 0.5818931 , 0.93400913, 0.5377912 , 0.10219802,\n",
       "       0.10610287, 0.15595432, 0.09624977, 0.22837757, 0.6161129 ,\n",
       "       0.57399214, 0.10613587, 0.1151635 , 0.83857736, 0.88188766,\n",
       "       0.69681406, 0.82287723, 0.48885519, 0.32749895, 0.17005035,\n",
       "       0.93445101, 0.47075196, 0.09137056, 0.10613495, 0.16785703,\n",
       "       0.81579371, 0.7811385 , 0.48260567, 0.60605735, 0.06641076,\n",
       "       0.26302075, 0.76505331, 0.25509033, 0.09052427, 0.73897216,\n",
       "       0.11529971, 0.05255997, 0.09914966, 0.54071172, 0.65394854,\n",
       "       0.36473283, 0.61610097, 0.07853734, 0.06053884, 0.06854522,\n",
       "       0.35699214, 0.11866573, 0.54042341, 0.64824985, 0.52386837,\n",
       "       0.50831684, 0.93063902, 0.95297919, 0.79697862, 0.10877674,\n",
       "       0.05325439, 0.94173599, 0.89574293, 0.04482112, 0.07835104,\n",
       "       0.0904971 , 0.07835104, 0.53468421, 0.10988999, 0.19261947,\n",
       "       0.90770563, 0.87091843, 0.29433581, 0.90048261, 0.06887416,\n",
       "       0.17979235, 0.4959198 , 0.66055925, 0.10613587, 0.95649267,\n",
       "       0.68449596, 0.1003097 , 0.4338489 , 0.04245879, 0.20895765,\n",
       "       0.72505058, 0.08035039, 0.90448723, 0.95407399, 0.61613674,\n",
       "       0.07835539, 0.25075913, 0.58994821, 0.22605419, 0.11532625,\n",
       "       0.94508762, 0.5736032 , 0.97110051, 0.08010842, 0.22123313,\n",
       "       0.61610097, 0.59802572, 0.82030466, 0.9707412 , 0.07835104,\n",
       "       0.43423951, 0.68279092, 0.38863728, 0.02885612, 0.62687383,\n",
       "       0.17758572, 0.8257206 , 0.21705726, 0.9095775 , 0.07835104,\n",
       "       0.31443654, 0.0979166 , 0.10539414, 0.71996393, 0.79255332,\n",
       "       0.40386497, 0.57293683, 0.11558777])"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "#Here, we get two values, prediction for both the classes. For further calculations, we need a list of only 1 probability for calculation\n",
    "\n",
    "train_preds = train_predict_proba[:,1]\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(train_preds)):\n",
    "  if(train_preds[i]>0.55):\n",
    "    train_preds[i] = 1\n",
    "  else:\n",
    "    train_preds[i] = 0\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training f1_score 0.7622950819672131\n"
     ]
    }
   ],
   "source": [
    "# Calculating f1-score\n",
    "k = f1_score(train_preds, train_y)\n",
    "print('Training f1_score', k )"
   ]
  },
  {
   "source": [
    "## Confusion Metrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[122,  21],\n",
       "       [ 29,  51]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(test_y, predicted_test)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.81      0.85      0.83       143\n           1       0.71      0.64      0.67        80\n\n    accuracy                           0.78       223\n   macro avg       0.76      0.75      0.75       223\nweighted avg       0.77      0.78      0.77       223\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y, predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters of Logistic Regression"
   ]
  }
 ]
}